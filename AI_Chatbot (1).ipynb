{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rQsjm40-l7y",
        "outputId": "0753b283-a4d3-4eca-9a63-4721ea693644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.118.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import json\n",
        "import gradio as gr\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5ZW889U-6En",
        "outputId": "26f30e11-a3c8-4c42-e170-c652dcd09c09"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_data = [\n",
        "    {\"question\": \"Hello\", \"answer\": \"Hi there! How can I help you?\"},\n",
        "    {\"question\": \"Hi\", \"answer\": \"Hello! What can I do for you?\"},\n",
        "    {\"question\": \"What is your name?\", \"answer\": \"I am Shipun AI Chatbot.\"},\n",
        "    {\"question\": \"How are you?\", \"answer\": \"I am fine, thank you! How are you?\"},\n",
        "    {\"question\": \"What do you do?\", \"answer\": \"I am here to answer your questions.\"},\n",
        "    {\"question\": \"Who created you?\", \"answer\": \"I was created by Shipun Meher.\"},\n",
        "    {\"question\": \"Tell me a joke\", \"answer\": \"Why did the computer go to the doctor? It caught a virus!\"},\n",
        "    {\"question\": \"What is Python?\", \"answer\": \"Python is a high-level, interpreted programming language.\"},\n",
        "    {\"question\": \"What is Data Science?\", \"answer\": \"Data Science is the field of extracting insights from data.\"},\n",
        "    {\"question\": \"What is AI?\", \"answer\": \"AI stands for Artificial Intelligence, which enables machines to think.\"},\n",
        "    {\"question\": \"What is Machine Learning?\", \"answer\": \"Machine Learning is a subset of AI focused on data-driven predictions.\"},\n",
        "    {\"question\": \"Who is Elon Musk?\", \"answer\": \"Elon Musk is the CEO of Tesla and SpaceX.\"},\n",
        "    {\"question\": \"What is your favorite color?\", \"answer\": \"I like all colors equally!\"},\n",
        "    {\"question\": \"Goodbye\", \"answer\": \"Goodbye! Have a nice day!\"},\n",
        "    {\"question\": \"Bye\", \"answer\": \"See you later!\"},\n",
        "    {\"question\": \"Thanks\", \"answer\": \"Youâ€™re welcome!\"},\n",
        "    {\"question\": \"Thank you\", \"answer\": \"No problem!\"},\n",
        "    {\"question\": \"What is your purpose?\", \"answer\": \"I am designed to help and chat with users.\"},\n",
        "    {\"question\": \"Can you help me?\", \"answer\": \"Of course! Ask me anything.\"},\n",
        "    {\"question\": \"What is a chatbot?\", \"answer\": \"A chatbot is a program designed to simulate conversation with humans.\"},\n",
        "    {\"question\": \"What is deep learning?\", \"answer\": \"Deep learning is a subset of ML that uses neural networks.\"},\n",
        "    {\"question\": \"Tell me about SRIMS Telecom\", \"answer\": \"SRIMS Telecom is a concept used for customer churn prediction and analysis.\"},\n",
        "    {\"question\": \"What is customer churn?\", \"answer\": \"Customer churn is when customers stop using a service.\"},\n",
        "    {\"question\": \"What is object detection?\", \"answer\": \"Object detection identifies objects in images or videos.\"},\n",
        "    {\"question\": \"What is YOLO?\", \"answer\": \"YOLO is a real-time object detection system.\"},\n",
        "    {\"question\": \"How can I learn Python?\", \"answer\": \"You can start learning Python by practicing on online platforms like Kaggle or Codecademy.\"},\n",
        "    {\"question\": \"What is Power BI?\", \"answer\": \"Power BI is a business analytics tool by Microsoft.\"},\n",
        "    {\"question\": \"What is SQL?\", \"answer\": \"SQL is a language used to communicate with databases.\"},\n",
        "    {\"question\": \"What is a dataframe?\", \"answer\": \"A dataframe is a table-like data structure in Python pandas.\"},\n",
        "    {\"question\": \"What is a neural network?\", \"answer\": \"A neural network is a computational model inspired by the human brain.\"},\n",
        "    {\"question\": \"What is supervised learning?\", \"answer\": \"Supervised learning is ML where the model is trained on labeled data.\"},\n",
        "    {\"question\": \"What is unsupervised learning?\", \"answer\": \"Unsupervised learning finds patterns in unlabeled data.\"},\n",
        "    {\"question\": \"What is regression?\", \"answer\": \"Regression predicts continuous numeric values.\"},\n",
        "    {\"question\": \"What is classification?\", \"answer\": \"Classification predicts categories or labels.\"},\n",
        "    {\"question\": \"What is overfitting?\", \"answer\": \"Overfitting is when a model performs well on training data but poorly on new data.\"},\n",
        "    {\"question\": \"What is underfitting?\", \"answer\": \"Underfitting is when a model cannot capture the patterns in data.\"},\n",
        "    {\"question\": \"What is a confusion matrix?\", \"answer\": \"A confusion matrix is a table to evaluate classification models.\"},\n",
        "    {\"question\": \"What is accuracy?\", \"answer\": \"Accuracy is the ratio of correctly predicted observations to total observations.\"},\n",
        "    {\"question\": \"What is precision?\", \"answer\": \"Precision is the ratio of correctly predicted positive observations to total predicted positives.\"},\n",
        "    {\"question\": \"What is recall?\", \"answer\": \"Recall is the ratio of correctly predicted positive observations to all actual positives.\"},\n",
        "]\n"
      ],
      "metadata": {
        "id": "_RBvnsCP-9Wr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "hOcAxJiv_Edm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    user_input_processed = preprocess_text(user_input)\n",
        "\n",
        "    # Find best match using simple word overlap\n",
        "    best_score = 0\n",
        "    best_answer = \"I am sorry, I don't understand that.\"\n",
        "\n",
        "    for qa in qa_data:\n",
        "        question_processed = preprocess_text(qa[\"question\"])\n",
        "        # Simple scoring: number of common words\n",
        "        score = len(set(user_input_processed.split()) & set(question_processed.split()))\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_answer = qa[\"answer\"]\n",
        "\n",
        "    return best_answer\n"
      ],
      "metadata": {
        "id": "H9YrKd1v_K7e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
        "        print(\"Shipun AI Chatbot: Goodbye!\")\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(\"Shipun AI Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrm_XL0O_MdX",
        "outputId": "ef25b98b-7c21-43b6-b74d-734c8bc422d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: Hello\n",
            "Shipun AI Chatbot: Hi there! How can I help you?\n",
            "You: what is machine learning\n",
            "Shipun AI Chatbot: Machine Learning is a subset of AI focused on data-driven predictions.\n",
            "You: quit\n",
            "Shipun AI Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_interface(user_input):\n",
        "    return chatbot_response(user_input)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=chat_interface,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Ask me something...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Shipun AI Chatbot\",\n",
        "    description=\"Chat with Shipun AI Chatbot Q&A\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "csDbC4Sv_QFQ",
        "outputId": "1ed89570-92b1-42ee-8a9e-ff43342974a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a7ab4f9ad6555a17c9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a7ab4f9ad6555a17c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-i6lW4Uq_gMu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}